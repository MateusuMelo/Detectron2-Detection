{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275263ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install shutup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa4eb51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4abc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python==4.6.0.66 in /home/appuser/.local/lib/python3.8/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/appuser/.local/lib/python3.8/site-packages (from opencv-python==4.6.0.66) (1.24.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib==3.5.3 in /home/appuser/.local/lib/python3.8/site-packages (3.5.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/appuser/.local/lib/python3.8/site-packages (from matplotlib==3.5.3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/appuser/.local/lib/python3.8/site-packages (from matplotlib==3.5.3) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/appuser/.local/lib/python3.8/site-packages (from matplotlib==3.5.3) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/appuser/.local/lib/python3.8/site-packages (from matplotlib==3.5.3) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/appuser/.local/lib/python3.8/site-packages (from matplotlib==3.5.3) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/appuser/.local/lib/python3.8/site-packages (from matplotlib==3.5.3) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/appuser/.local/lib/python3.8/site-packages (from matplotlib==3.5.3) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/appuser/.local/lib/python3.8/site-packages (from matplotlib==3.5.3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/appuser/.local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib==3.5.3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-python==4.6.0.66\n",
    "#!pip install matplotlib==3.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c74a377-68af-475e-b762-5fcb1b36f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/facebookresearch/detectron2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c4fe25-5cc4-493e-a5ee-1060757e933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pillow>=7.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0b6bf-1d3c-49af-9f2d-f6ba20b59235",
   "metadata": {},
   "source": [
    "## Cria um .json que precisa para levantar as métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "401621ea-36b4-46a1-a3f6-b103384c1a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anotações convertidas e salvas em data/test/annotations.json\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "# import os\n",
    "# from detectron2.structures import BoxMode\n",
    "\n",
    "# # Defina o caminho para a pasta de anotações e imagens\n",
    "# annotations_dir = \"data/test/labels\"\n",
    "# images_dir = \"data/test/images\"\n",
    "\n",
    "# # Lista de imagens no diretório de imagens\n",
    "# image_file_names = os.listdir(images_dir)\n",
    "\n",
    "# # Inicialize a lista de anotações\n",
    "# annotations = []\n",
    "\n",
    "# # Função para carregar rótulos a partir dos arquivos\n",
    "# def load_labels(image_name):\n",
    "#     label_file = os.path.join(test_labels_dir, os.path.splitext(image_name)[0] + \".txt\")\n",
    "#     with open(label_file, \"r\") as file:\n",
    "#         labels = file.read().strip().split(\"\\n\")\n",
    "#     labels = [label.split() for label in labels]\n",
    "#     labels = np.array(labels).astype(float)  # Substitua np.float por float\n",
    "#     return labels\n",
    "\n",
    "# # Loop através das imagens\n",
    "# for image_name in image_file_names:\n",
    "#     image_path = os.path.join(images_dir, image_name)\n",
    "#     height, width = cv2.imread(image_path).shape[:2]\n",
    "\n",
    "#     # Carregue as anotações do arquivo YOLOv5\n",
    "#     labels = load_labels(image_name)\n",
    "\n",
    "#     # Converta as anotações do YOLOv5 para o formato BoxMode do Detectron2\n",
    "#     image_id = image_name  # Use o nome da imagem como ID (você pode ajustar isso conforme necessário)\n",
    "#     image_info = {\n",
    "#         \"file_name\": os.path.join(images_dir, image_name),\n",
    "#         \"height\": height,\n",
    "#         \"width\": width,\n",
    "#         \"image_id\": image_id,\n",
    "#     }\n",
    "#     image_info[\"annotations\"] = []\n",
    "\n",
    "#     for label in labels:\n",
    "#         x_center, y_center, box_width, box_height, class_id = label\n",
    "#         x_min = (x_center - box_width / 2) * width\n",
    "#         y_min = (y_center - box_height / 2) * height\n",
    "#         x_max = (x_center + box_width / 2) * width\n",
    "#         y_max = (y_center + box_height / 2) * height\n",
    "\n",
    "#         annotation = {\n",
    "#             \"bbox\": [x_min, y_min, x_max, y_max],\n",
    "#             \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "#             \"category_id\": int(class_id),\n",
    "#         }\n",
    "#         image_info[\"annotations\"].append(annotation)\n",
    "\n",
    "#     annotations.append(image_info)\n",
    "\n",
    "# # Salve as anotações em um arquivo JSON\n",
    "# output_json_file = \"data/test/annotations.json\"\n",
    "# with open(output_json_file, \"w\") as json_file:\n",
    "#     json.dump(annotations, json_file)\n",
    "\n",
    "# print(f\"Anotações convertidas e salvas em {output_json_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354dadf2-8f7c-4086-8aa9-21304f767775",
   "metadata": {},
   "source": [
    "## Gerar .txt com cada um dos modelos Detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e303dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import Metadata\n",
    "\n",
    "# Define o número do modelo treinado\n",
    "model_number = \"2\"  # Altere o número do modelo conforme necessário\n",
    "\n",
    "# Crie o caminho para o diretório de saída com base no número do modelo\n",
    "output_dir = f\"./output/modelotreinado{model_number}\"\n",
    "\n",
    "# Carregue o modelo treinado\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_50_DC5_1x.yaml'))\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
    "cfg.MODEL.WEIGHTS = os.path.join(output_dir, \"model_final.pth\")\n",
    "cfg.MODEL.DEVICE = 'cuda'  # Use GPU\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.6  # Ajuste o limite NMS conforme necessário\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Ajuste o limite de confiança conforme necessário\n",
    "cfg.MODEL.ROI_HEADS.NUM_DETECTIONS = 1  # Limite uma detecção por imagem\n",
    "\n",
    "# Crie um predictor\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Caminho para as imagens de teste\n",
    "test_images_dir = \"./data/test/images\"\n",
    "\n",
    "# Lista de nomes de arquivo de imagens\n",
    "image_file_names = os.listdir(test_images_dir)\n",
    "\n",
    "import os\n",
    "\n",
    "# Criar o diretório de saída, se não existir\n",
    "output_dir = f\"./modelosaida{model_number}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop sobre as imagens selecionadas\n",
    "for image_name in image_file_names:\n",
    "    image_path = os.path.join(test_images_dir, image_name)\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Faça a previsão\n",
    "    outputs = predictor(img)\n",
    "        \n",
    "    # Forçar a seleção da detecção mais confiante\n",
    "    outputs[\"instances\"] = outputs[\"instances\"][:1]\n",
    "\n",
    "    # Extrair informações\n",
    "    pred_boxes = outputs['instances'].to('cpu').pred_boxes.tensor\n",
    "    pred_classes = outputs['instances'].to('cpu').pred_classes\n",
    "\n",
    "    # Obter a largura e altura da imagem original\n",
    "    image_width = img.shape[1]  # Largura da imagem original\n",
    "    image_height = img.shape[0]  # Altura da imagem original\n",
    "\n",
    "    # Converter as posições para o formato YOLOv5 (x_center, y_center, width, height)\n",
    "    box = pred_boxes[0]  # Pegar a primeira (e única) caixa\n",
    "    x_center = (box[0] + box[2]) / 2 / image_width\n",
    "    y_center = (box[1] + box[3]) / 2 / image_height\n",
    "    width = (box[2] - box[0]) / image_width\n",
    "    height = (box[3] - box[1]) / image_height\n",
    "\n",
    "    # Resultado a ser salvo no arquivo .txt\n",
    "    result = f\"{pred_classes[0]} {x_center} {y_center} {width} {height}\"\n",
    "    \n",
    "    # Nome do arquivo .txt a ser salvo\n",
    "    txt_filename = os.path.splitext(image_name)[0] + \".txt\"\n",
    "    \n",
    "    # Caminho completo para o arquivo .txt\n",
    "    txt_filepath = os.path.join(output_dir, txt_filename)\n",
    "    \n",
    "    # Salvar o resultado no arquivo .txt\n",
    "    with open(txt_filepath, \"w\") as txt_file:\n",
    "        txt_file.write(result)\n",
    "    \n",
    "    # Converter de BGR para RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Definir as classes desejadas\n",
    "    custom_classes = [\n",
    "        \"BULK CARRIER\",\n",
    "        \"CONTAINER SHIP\",\n",
    "        \"GENERAL CARGO\",\n",
    "        \"OIL PRODUCTS TANKER\",\n",
    "        \"PASSENGERS SHIP\",\n",
    "        \"TANKER\",\n",
    "        \"TRAWLER\",\n",
    "        \"TUG\",\n",
    "        \"VEHICLES CARRIER\",\n",
    "        \"YACHT\"\n",
    "    ]\n",
    "    \n",
    "    # Criar um Metadata personalizado\n",
    "    custom_metadata = Metadata()\n",
    "    custom_metadata.thing_classes = custom_classes\n",
    "    \n",
    "    # Criar o visualizador com o Metadata personalizado\n",
    "    v = Visualizer(img_rgb, custom_metadata, scale=1.2)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    # Plote a imagem com as previsões usando matplotlib\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
